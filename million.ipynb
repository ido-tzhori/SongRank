{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import re\n",
    "from collections import *\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from scipy.sparse import csr_matrix\n",
    "import time\n",
    "import random\n",
    "import webbrowser\n",
    "import pickle, gzip, joblib, shelve\n",
    "import tkinter as tk\n",
    "from tkinter import ttk, font\n",
    "import threading, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000 playlists\n"
     ]
    }
   ],
   "source": [
    "directory_path = 'data/raw'\n",
    "filenames = sorted(os.listdir(directory_path))\n",
    "print(f\"{len(filenames) * 1000} playlists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# looking at only the first 30,000 playlists\n",
    "fullpaths = [directory_path + '/' + f for f in filenames][0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_tracks_per_playlist = 5\n",
    "max_tracks_per_playlist = 150\n",
    "min_albums_per_playlist = 2\n",
    "min_artists_per_playlist = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# song_relationships = {}\n",
    "\n",
    "# t = 0\n",
    "# iteration_times = []\n",
    "\n",
    "# for idx, path in enumerate(fullpaths):\n",
    "#     start_time = time.time()\n",
    "#     if idx % 5 == 0 and idx > 0:\n",
    "#         print(f\"processed {idx-5}-{idx} - time taken {t:.2f}\")\n",
    "#         iteration_times.append(t)\n",
    "#         t = 0\n",
    "#     with open(path) as f:\n",
    "#         mpd_slice = json.load(f)\n",
    "#     playlists_data = mpd_slice['playlists']\n",
    "\n",
    "#     for idx, playlist in enumerate(playlists_data):\n",
    "#         # r = playlist['num_albums'] / playlist['num_tracks']\n",
    "#         # if r < 0.0:\n",
    "#         #     continue\n",
    "#         songs = set(track['track_uri'] for track in playlist['tracks'])\n",
    "#         t_per_p = len(songs)\n",
    "#         albums = set(track['album_uri'] for track in playlist['tracks'])\n",
    "#         alb_per_p = len(albums)\n",
    "#         artists = set(track['artist_uri'] for track in playlist['tracks'])\n",
    "#         art_per_p = len(artists)\n",
    "\n",
    "#         if (min_tracks_per_playlist >= t_per_p) or \\\n",
    "#              (t_per_p >= max_tracks_per_playlist) or \\\n",
    "#                 (min_albums_per_playlist >= alb_per_p) or \\\n",
    "#                     (min_artists_per_playlist >= art_per_p):\n",
    "#             continue\n",
    "\n",
    "#         for song in songs:\n",
    "#             if song not in song_relationships:\n",
    "#                 song_relationships[song] = {}\n",
    "                \n",
    "#             for related_song in songs:\n",
    "#                 if related_song != song:  # avoid self-relationship\n",
    "#                     if related_song in song_relationships[song]:\n",
    "#                         song_relationships[song][related_song] += 1\n",
    "#                     else:\n",
    "#                         song_relationships[song][related_song] = 1\n",
    "#     end_time = time.time()\n",
    "#     t += end_time - start_time\n",
    "\n",
    "# print(f'Number of songs processed: {len(song_relationships)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 0-10 - time taken 17.60\n",
      "processed 10-20 - time taken 21.18\n",
      "processed 20-30 - time taken 21.06\n",
      "processed 30-40 - time taken 21.40\n",
      "processed 40-50 - time taken 22.20\n",
      "processed 50-60 - time taken 25.65\n",
      "processed 60-70 - time taken 23.48\n",
      "processed 70-80 - time taken 24.03\n",
      "processed 80-90 - time taken 24.21\n",
      "processed 90-100 - time taken 25.43\n",
      "processed 100-110 - time taken 27.53\n",
      "processed 110-120 - time taken 29.41\n",
      "processed 120-130 - time taken 34.93\n",
      "processed 130-140 - time taken 40.51\n",
      "processed 140-150 - time taken 42.18\n",
      "processed 150-160 - time taken 46.70\n",
      "processed 160-170 - time taken 51.54\n",
      "processed 170-180 - time taken 54.33\n",
      "processed 180-190 - time taken 55.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 821079/821079 [06:31<00:00, 2098.76it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "821079 songs processed\n",
      "'song_relationships' saved to song_data/song_relationships.gz\n"
     ]
    }
   ],
   "source": [
    "song_relationships = {}\n",
    "\n",
    "t = 0\n",
    "iteration_times = []\n",
    "\n",
    "for idx, path in enumerate(fullpaths):\n",
    "    start_time = time.time()\n",
    "    if idx % 10 == 0 and idx > 0:\n",
    "        print(f\"processed {idx-10}-{idx} - time taken {t:.2f}\")\n",
    "        iteration_times.append(t)\n",
    "        t = 0\n",
    "    with open(path) as f:\n",
    "        mpd_slice = json.load(f)\n",
    "    playlists_data = mpd_slice['playlists']\n",
    "\n",
    "    for idx, playlist in enumerate(playlists_data):\n",
    "        # r = playlist['num_albums'] / playlist['num_tracks']\n",
    "        # if r < 0.0:\n",
    "        #     continue\n",
    "        songs = set(track['track_uri'] for track in playlist['tracks'])\n",
    "        t_per_p = len(songs)\n",
    "        albums = set(track['album_uri'] for track in playlist['tracks'])\n",
    "        alb_per_p = len(albums)\n",
    "        artists = set(track['artist_uri'] for track in playlist['tracks'])\n",
    "        art_per_p = len(artists)\n",
    "\n",
    "        if (min_tracks_per_playlist >= t_per_p) or \\\n",
    "             (t_per_p >= max_tracks_per_playlist) or \\\n",
    "                (min_albums_per_playlist >= alb_per_p) or \\\n",
    "                    (min_artists_per_playlist >= art_per_p):\n",
    "            continue\n",
    "        \n",
    "        temp_relationships = {}\n",
    "\n",
    "        for song in songs:\n",
    "            if song not in temp_relationships:\n",
    "                temp_relationships[song] = {}\n",
    "            \n",
    "            for related_song in songs:\n",
    "                if related_song != song:  # avoid self-relationship\n",
    "                    if related_song in temp_relationships[song]:\n",
    "                        temp_relationships[song][related_song] += 1\n",
    "                    else:\n",
    "                        temp_relationships[song][related_song] = 1\n",
    "\n",
    "        for song, relations in temp_relationships.items():\n",
    "            if song not in song_relationships:\n",
    "                song_relationships[song] = dict(relations)\n",
    "            else:\n",
    "                for related_song, count in relations.items():\n",
    "                    if related_song in song_relationships[song]:\n",
    "                        song_relationships[song][related_song] += count\n",
    "                    else:\n",
    "                        song_relationships[song][related_song] = count\n",
    "\n",
    "    end_time = time.time()\n",
    "    t += end_time - start_time\n",
    "\n",
    "song_relationships = {key: list(value.items()) for key, value in tqdm(song_relationships.items())}\n",
    "    \n",
    "print(f'{len(song_relationships)} songs processed')\n",
    "\n",
    "# save_path = os.path.join('song_data', 'song_relationships.gz')\n",
    "\n",
    "# with gzip.open(save_path, 'wb') as f:\n",
    "#     pickle.dump(song_relationships, f, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "# print(f\"'song_relationships' saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load song_relationships from storage\n",
    "\n",
    "save_path = os.path.join('song_data', 'song_relationships.gz')\n",
    "\n",
    "with gzip.open(save_path, 'rb') as f:\n",
    "    song_relationships = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0-10\n",
      "Processed 10-20\n",
      "Processed 20-30\n",
      "Processed 30-40\n",
      "Processed 40-50\n",
      "Processed 50-60\n",
      "Processed 60-70\n",
      "Processed 70-80\n",
      "Processed 80-90\n",
      "Processed 90-100\n",
      "Processed 100-110\n",
      "Processed 110-120\n",
      "Processed 120-130\n",
      "Processed 130-140\n",
      "Processed 140-150\n",
      "Processed 150-160\n",
      "Processed 160-170\n",
      "Processed 170-180\n",
      "Processed 180-190\n",
      "'song_data_map' saved to song_data/song_data_map.pkl\n"
     ]
    }
   ],
   "source": [
    "song_data_map = {}\n",
    "for idx, path in enumerate(fullpaths):\n",
    "    if idx % 10 == 0 and idx > 0:\n",
    "        print(f\"Processed {idx-10}-{idx}\")\n",
    "    with open(path) as f:\n",
    "        mpd_slice = json.load(f)\n",
    "    playlists_data = mpd_slice['playlists']\n",
    "    for playlist in playlists_data:\n",
    "        for track in playlist['tracks']:\n",
    "            song_uri = track['track_uri']\n",
    "            song_name = track['track_name']\n",
    "            album_name = track['album_name']\n",
    "            artist_name = track['artist_name']\n",
    "            if song_uri in song_relationships:\n",
    "                song_data_map[song_uri] = {'song_name': song_name, 'album_name': album_name, 'artist_name': artist_name}\n",
    "\n",
    "save_path = os.path.join('song_data', 'song_data_map.gz')\n",
    "\n",
    "with gzip.open(save_path, 'wb') as f:\n",
    "    pickle.dump(song_data_map, f)\n",
    "print(f\"'song_data_map' saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load song_data_map from storage\n",
    "\n",
    "save_path = os.path.join('song_data', 'song_data_map.gz')\n",
    "\n",
    "with gzip.open(save_path, 'rb') as f:\n",
    "    song_data_map = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song with the most connections: {'song_name': 'Closer', 'album_name': 'Closer', 'artist_name': 'The Chainsmokers'}\n",
      "Number of connections: 60039\n"
     ]
    }
   ],
   "source": [
    "max_connections = 0\n",
    "song_with_most_connections = None\n",
    "\n",
    "for song, connections in song_relationships.items():\n",
    "    num_connections = len(connections)\n",
    "    if num_connections > max_connections:\n",
    "        max_connections = num_connections\n",
    "        song_with_most_connections = song\n",
    "\n",
    "print(\"Song with the most connections:\", song_data_map[song_with_most_connections])\n",
    "print(\"Number of connections:\", max_connections)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_indices = {song_uri: idx for idx, song_uri in enumerate(song_relationships.keys())}\n",
    "num_songs = len(song_relationships)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 30000 rows.....\n",
      "Processed 60000 rows.....\n",
      "Processed 90000 rows.....\n",
      "Processed 120000 rows.....\n",
      "Processed 150000 rows.....\n",
      "Processed 180000 rows.....\n",
      "Processed 210000 rows.....\n",
      "Processed 240000 rows.....\n",
      "Processed 270000 rows.....\n",
      "Processed 300000 rows.....\n",
      "Processed 330000 rows.....\n",
      "Processed 360000 rows.....\n",
      "Processed 390000 rows.....\n",
      "Processed 420000 rows.....\n",
      "Processed 450000 rows.....\n",
      "Processed 480000 rows.....\n",
      "Processed 510000 rows.....\n",
      "Processed 540000 rows.....\n",
      "Processed 570000 rows.....\n",
      "Processed 600000 rows.....\n",
      "Processed 630000 rows.....\n",
      "Processed 660000 rows.....\n",
      "Processed 690000 rows.....\n",
      "Processed 720000 rows.....\n",
      "Processed 750000 rows.....\n",
      "Processed 780000 rows.....\n",
      "Processed 810000 rows.....\n",
      "'cooccurrence_matrix' saved to song_data/cooccurrence_matrix.pkl\n"
     ]
    }
   ],
   "source": [
    "row_indices = []\n",
    "col_indices = []\n",
    "data_sum = []\n",
    "data = []\n",
    "\n",
    "for idx, (song_uri, relationships) in enumerate(song_relationships.items()):\n",
    "    row_idx = song_indices[song_uri]\n",
    "    # sum_connections = np.sum([x[1] for x in relationships])\n",
    "    for related_song_uri, count in relationships:\n",
    "        col_idx = song_indices[related_song_uri]\n",
    "        row_indices.append(row_idx)\n",
    "        col_indices.append(col_idx)\n",
    "        # data_sum.append(count / sum_connections)\n",
    "        data.append(count)\n",
    "\n",
    "    if idx % 30000 == 0 and idx > 0:\n",
    "        print(f\"Processed {idx} rows.....\")\n",
    "\n",
    "# transition_matrix = csr_matrix((data_sum, (row_indices, col_indices)), shape=(num_songs, num_songs), dtype=np.float64)\n",
    "cooccurrence_matrix = csr_matrix((data, (row_indices, col_indices)), shape=(num_songs, num_songs), dtype=np.float64)\n",
    "\n",
    "save_path = os.path.join('song_data', 'cooccurrence_matrix.gz')\n",
    "with gzip.open(save_path, 'wb') as f:\n",
    "    pickle.dump(cooccurrence_matrix, f)\n",
    "print(f\"'cooccurrence_matrix' saved to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load cooccurrence_matrix from storage\n",
    "\n",
    "save_path = os.path.join('song_data', 'cooccurrence_matrix.gz')\n",
    "\n",
    "with gzip.open(save_path, 'rb') as f:\n",
    "    cooccurrence_matrix = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n = 10\n",
    "\n",
    "popularity = np.sum(transition_matrix, axis=0)\n",
    "top_n_indices = np.argsort(popularity.A1)[-n:]\n",
    "\n",
    "init = np.random.rand(1, num_songs)\n",
    "init = init / np.sum(init)\n",
    "probs = [init]\n",
    "p = csr_matrix(init)\n",
    "\n",
    "damping = True\n",
    "if damping:\n",
    "    damping_factor = 0.85\n",
    "    random_jump_vector = csr_matrix(np.ones(num_songs)/num_songs)\n",
    "    for i in tqdm(range(30)):\n",
    "        p = damping_factor * np.dot(p, transition_matrix) + (1 - damping_factor) * random_jump_vector\n",
    "        probs.append(p)\n",
    "else:\n",
    "    for i in tqdm(range(30)):\n",
    "        p = np.dot(p, transition_matrix)\n",
    "        probs.append(p)\n",
    "\n",
    "\n",
    "plot_data = []\n",
    "for i in top_n_indices:\n",
    "    song_name = song_data_map[list(song_relationships)[i]][\"song_name\"]\n",
    "    for step_num, step in enumerate(probs):\n",
    "        plot_data.append({'Iteration': step_num, 'Probability': step[0, i], 'Song': song_name})\n",
    "\n",
    "df = pd.DataFrame(plot_data)\n",
    "fig = px.line(df, x='Iteration', y='Probability', color='Song', title='Convergence of Most Popular Songs')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A = transition_matrix.copy()\n",
    "# def user_playlist_vector(playlist_songs, song_indices, num_songs):\n",
    "#     user_vector = np.zeros(num_songs)\n",
    "#     for song in playlist_songs:\n",
    "#         user_vector[song_indices[song]] = 1/len(playlist_songs)\n",
    "#     return csr_matrix(user_vector)\n",
    "\n",
    "# def get_recommendation_vector(user_vector, transition_matrix, steps, damping = True, damping_factor = 0.0):\n",
    "#     p = user_vector\n",
    "#     if damping:\n",
    "#         random_jump_vector = csr_matrix(np.ones(num_songs) / num_songs)\n",
    "#         for _ in range(steps):\n",
    "#             p = damping_factor * np.dot(p, transition_matrix) + (1 - damping_factor) * user_vector\n",
    "#     else:\n",
    "#         for _ in range(steps):\n",
    "#             p = np.dot(p, transition_matrix)\n",
    "#     return p.toarray()[0]\n",
    "\n",
    "# def top_n_recommendations(recommendation_vector, song_data_map, n):\n",
    "#     top_indices = np.argsort(recommendation_vector)[-n:]\n",
    "#     top_songs = [song_data_map[list(song_relationships)[i]] for i in top_indices]\n",
    "#     return top_songs\n",
    "\n",
    "# def recommend_songs(user_playlist, song_indices, transition_matrix, song_data_map, steps, n=10):\n",
    "#     user_vector = user_playlist_vector(user_playlist, song_indices, len(song_indices))\n",
    "#     recommendation_vector = get_recommendation_vector(user_vector, transition_matrix, steps)\n",
    "#     return top_n_recommendations(recommendation_vector, song_data_map, n)\n",
    "\n",
    "# top_n_songs = [list(song_relationships)[i] for i in top_n_indices]\n",
    "# playlist = random.sample(list(song_relationships), 3) #+ top_n_songs\n",
    "\n",
    "# for i, j in zip(playlist, [song_data_map[x] for x in playlist]):\n",
    "#     print(i, j)\n",
    "\n",
    "# recommended_songs = recommend_songs(playlist, song_indices, A, song_data_map, 10, n=5)\n",
    "# for song in recommended_songs:\n",
    "#     print(f\"Song: {song['song_name']}\\nAlbum: {song['album_name']}\\nArtist: {song['artist_name']}\\n{'-'*40}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 821079/821079 [16:23<00:00, 834.48it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'pmi_matrix' saved to song_data/pmi_matrix.gz\n"
     ]
    }
   ],
   "source": [
    "total_occurrences = np.sum(cooccurrence_matrix)\n",
    "p_i = np.sum(cooccurrence_matrix, axis=1) / total_occurrences\n",
    "p_i = np.asarray(p_i).flatten()  # Convert matrix to 1D array\n",
    "p_ij = cooccurrence_matrix / total_occurrences\n",
    "\n",
    "pmi_data = np.array(p_ij.data)\n",
    "k = 1\n",
    "\n",
    "for i in tqdm(range(len(p_ij.indptr) - 1)):\n",
    "    for data_idx in range(p_ij.indptr[i], p_ij.indptr[i + 1]):\n",
    "        j = p_ij.indices[data_idx]\n",
    "        if pmi_data[data_idx] > 0:  # Avoid log(0)\n",
    "            original_pmi = np.log2(pmi_data[data_idx] / (p_i[i] * p_i[j]))\n",
    "            pmi_data[data_idx] = original_pmi - (-(k - 1) * np.log2(pmi_data[data_idx]))\n",
    "        else:\n",
    "            pmi_data[data_idx] = 0  # Or any other default value for log(0)\n",
    "\n",
    "pmi_matrix = csr_matrix((pmi_data, p_ij.indices, p_ij.indptr), shape=cooccurrence_matrix.shape)\n",
    "\n",
    "save_path = os.path.join('song_data', 'pmi_matrix.gz')\n",
    "with gzip.open(save_path, 'wb') as f:\n",
    "    pickle.dump(pmi_matrix, f)\n",
    "print(f\"'pmi_matrix' saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load pmi_matrix from storage\n",
    "\n",
    "save_path = os.path.join('song_data', 'pmi_matrix.gz')\n",
    "\n",
    "with gzip.open(save_path, 'rb') as f:\n",
    "    pmi_matrix = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pmi_data = np.array(p_ij.data)\n",
    "\n",
    "# for i in tqdm(range(len(p_ij.indptr) - 1)):\n",
    "#     for data_idx in range(p_ij.indptr[i], p_ij.indptr[i + 1]):\n",
    "#         j = p_ij.indices[data_idx]\n",
    "#         if pmi_data[data_idx] > 0:  # Avoid log(0)\n",
    "#             pmi_data[data_idx] = np.log2(pmi_data[data_idx] / (p_i[i] * p_i[j]))\n",
    "#         else:\n",
    "#             pmi_data[data_idx] = 0  # Or any other default value for log(0)\n",
    "\n",
    "# pmi_matrix = csr_matrix((pmi_data, p_ij.indices, p_ij.indptr), shape=cooccurence_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_playlist_vector(playlist_songs, song_indices, num_songs):\n",
    "    user_vector = np.zeros(num_songs)\n",
    "    for song in playlist_songs:\n",
    "        user_vector[song_indices[song]] = 1\n",
    "    return csr_matrix(user_vector)\n",
    "\n",
    "def compute_scores(user_vector, pmi_matrix):\n",
    "    scores = user_vector.dot(pmi_matrix)\n",
    "    return scores.toarray()[0]\n",
    "\n",
    "def get_top_recommendations(scores, song_data_map, n=10):\n",
    "    top_indices = np.argsort(scores)[-n:]\n",
    "    top_songs = [song_data_map[list(song_relationships)[i]] for i in top_indices]\n",
    "    return top_songs\n",
    "\n",
    "def recommend_songs_pmi(user_playlist, song_indices, pmi_matrix, song_data_map, n=10):\n",
    "    user_vector = user_playlist_vector(user_playlist, song_indices, num_songs)\n",
    "    user_vector_csr = csr_matrix(user_vector)\n",
    "    scores = compute_scores(user_vector_csr, pmi_matrix)\n",
    "    return get_top_recommendations(scores, song_data_map, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SongRecommendationApp(tk.Tk):\n",
    "    def __init__(self, song_data_map):\n",
    "        super().__init__()\n",
    "\n",
    "        default_font = font.nametofont(\"TkDefaultFont\")\n",
    "        default_font.configure(family=\"Courier\")\n",
    "\n",
    "        self.song_data_map = song_data_map\n",
    "        self.uri_map = {self.format_song_display(song_info): uri for uri, song_info in song_data_map.items()}\n",
    "        self.playlist_data = []  # Store song data for sorting\n",
    "\n",
    "        # Filter Frame\n",
    "        self.filter_frame = ttk.Frame(self)\n",
    "        self.filter_frame.pack(pady=10)\n",
    "\n",
    "        # Label and Entry for Song\n",
    "        self.song_label = ttk.Label(self.filter_frame, text=\"Song\")\n",
    "        self.song_label.grid(row=0, column=0, padx=5)\n",
    "        self.song_entry = ttk.Entry(self.filter_frame)\n",
    "        self.song_entry.grid(row=1, column=0, padx=5)\n",
    "\n",
    "        # Label and Entry for Artist\n",
    "        self.artist_label = ttk.Label(self.filter_frame, text=\"Artist\")\n",
    "        self.artist_label.grid(row=0, column=1, padx=5)\n",
    "        self.artist_entry = ttk.Entry(self.filter_frame)\n",
    "        self.artist_entry.grid(row=1, column=1, padx=5)\n",
    "\n",
    "        # Label and Entry for Album\n",
    "        self.album_label = ttk.Label(self.filter_frame, text=\"Album\")\n",
    "        self.album_label.grid(row=0, column=2, padx=5)\n",
    "        self.album_entry = ttk.Entry(self.filter_frame)\n",
    "        self.album_entry.grid(row=1, column=2, padx=5)\n",
    "\n",
    "        # Debounce logic\n",
    "        self.last_time = time.time()\n",
    "\n",
    "        self.search_button = ttk.Button(self.filter_frame, text=\"Search\", command=self.display_search_results)\n",
    "        self.search_button.grid(row=2, columnspan=3, pady=10)\n",
    "\n",
    "        width = 200\n",
    "        # Songs Listbox\n",
    "        self.songs_listbox = tk.Listbox(self, selectmode=tk.SINGLE, width=width, font=(\"Courier\", 10))\n",
    "        self.songs_listbox.pack(pady=10)\n",
    "\n",
    "        # Drag & Drop functionality\n",
    "        self.songs_listbox.bind('<<ListboxSelect>>', self.add_to_playlist)\n",
    "\n",
    "        # Playlist Listbox\n",
    "        self.playlist_listbox = tk.Listbox(self, bg=\"lightblue\", selectmode=tk.SINGLE, width=width, font=(\"Courier\", 10))\n",
    "        self.playlist_listbox.pack(pady=10)\n",
    "\n",
    "        # Number of recommendations\n",
    "        self.n_label = ttk.Label(self, text=\"Number of Recommendations:\")\n",
    "        self.n_label.pack(pady=5)\n",
    "        self.n_entry = ttk.Entry(self)\n",
    "        self.n_entry.pack(pady=5)\n",
    "\n",
    "        # Button to generate recommendations\n",
    "        self.btn_recommend = ttk.Button(self, text=\"Generate Recommendations\", command=self.generate_recommendations)\n",
    "        self.btn_recommend.pack(pady=10)\n",
    "\n",
    "        # Recommendations Listbox\n",
    "        self.recommendations_listbox = tk.Listbox(self, bg=\"lightgreen\", selectmode=tk.SINGLE, width=width, font=(\"Courier\", 10))\n",
    "        self.recommendations_listbox.pack(pady=10)\n",
    "\n",
    "        self.recommendations_listbox.bind('<Double-Button-1>', self.open_in_spotify)\n",
    "\n",
    "        self.btn_refresh = ttk.Button(self, text=\"Refresh\", command=self.refresh)\n",
    "        self.btn_refresh.pack(pady=10)\n",
    "    \n",
    "    def refresh(self):\n",
    "        # Clear all fields\n",
    "        self.song_entry.delete(0, tk.END)\n",
    "        self.artist_entry.delete(0, tk.END)\n",
    "        self.album_entry.delete(0, tk.END)\n",
    "        self.n_entry.delete(0, tk.END)\n",
    "        \n",
    "        # Clear listboxes\n",
    "        self.songs_listbox.delete(0, tk.END)\n",
    "        self.playlist_listbox.delete(0, tk.END)\n",
    "        self.recommendations_listbox.delete(0, tk.END)\n",
    "\n",
    "    def open_in_spotify(self, event):\n",
    "            selected_index = self.recommendations_listbox.curselection()\n",
    "            if selected_index:\n",
    "                selected_song = self.recommendations_listbox.get(selected_index)\n",
    "                song_uri = self.uri_map[selected_song]\n",
    "                uri = song_uri.split(':')[-1]\n",
    "                webbrowser.open(f\"https://open.spotify.com/track/{uri}\")\n",
    "                \n",
    "    def display_search_results(self):\n",
    "        song_query = self.song_entry.get().lower()\n",
    "        artist_query = self.artist_entry.get().lower()\n",
    "        album_query = self.album_entry.get().lower()\n",
    "\n",
    "        self.songs_listbox.delete(0, tk.END)\n",
    "        results = []  # Store the filtered results first\n",
    "\n",
    "        for uri, song_info in self.song_data_map.items():\n",
    "            if song_query in song_info['song_name'].lower() and artist_query in song_info['artist_name'].lower() and album_query in song_info['album_name'].lower():\n",
    "                display_name = self.format_song_display(song_info)\n",
    "                results.append(display_name)\n",
    "\n",
    "        # Sort by album name\n",
    "        results.sort(key=lambda x: self.song_data_map[self.uri_map[x]]['album_name'])\n",
    "\n",
    "        # Display the sorted results\n",
    "        for display_name in results:\n",
    "            self.songs_listbox.insert(tk.END, display_name)\n",
    "\n",
    "        if len(results) > 200:  # If you want to limit the displayed results\n",
    "            self.songs_listbox.delete(201, tk.END)\n",
    "\n",
    "    def format_song_display(self, song_info):\n",
    "        formatted_str = \"{:<65}{:<35}{:<35}\"\n",
    "        f_string = formatted_str.format(song_info['song_name'], song_info['artist_name'], song_info['album_name'])\n",
    "        return f_string\n",
    "\n",
    "    def add_to_playlist(self, event):\n",
    "        selected_index = self.songs_listbox.curselection()\n",
    "        if selected_index:  # This checks if there's any selection at all\n",
    "            selected_song = self.songs_listbox.get(selected_index)\n",
    "            if selected_song not in self.playlist_listbox.get(0, tk.END):  # Prevent duplicates\n",
    "                self.playlist_listbox.insert(tk.END, selected_song)\n",
    "\n",
    "    def generate_recommendations(self):\n",
    "        playlist_display_names = list(self.playlist_listbox.get(0, tk.END))\n",
    "        playlist_uris = [self.uri_map[display_name] for display_name in playlist_display_names]  # Extract URIs\n",
    "\n",
    "        n = int(self.n_entry.get())\n",
    "        recommended_songs = recommend_songs_pmi(playlist_uris, song_indices, pmi_matrix, song_data_map, n)\n",
    "\n",
    "        self.recommendations_listbox.delete(0, tk.END)\n",
    "        for song in recommended_songs:\n",
    "            formatted_song = self.format_song_display(song)\n",
    "            self.recommendations_listbox.insert(tk.END, formatted_song)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = SongRecommendationApp(song_data_map)\n",
    "    app.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist = random.sample(list(song_relationships), 1)\n",
    "\n",
    "for i, j in zip(playlist, [song_data_map[x] for x in playlist]):\n",
    "    print(f\"Song: {j['song_name']}\\nAlbum: {j['album_name']}\\nArtist: {j['artist_name']}\\n{'-'*40}\")\n",
    "\n",
    "print(f'\\n{\"-\"*60}')\n",
    "recommended_songs = recommend_songs_pmi(playlist, song_indices, pmi_matrix, song_data_map, n=8)\n",
    "for song in recommended_songs:\n",
    "    print(f\"Song: {song['song_name']}\\nAlbum: {song['album_name']}\\nArtist: {song['artist_name']}\\n{'-'*40}\")    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
