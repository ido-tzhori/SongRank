{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import re\n",
    "from collections import *\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from scipy.sparse import csr_matrix, vstack, csr_array\n",
    "import time\n",
    "import random\n",
    "import webbrowser\n",
    "import pickle, gzip, joblib, shelve\n",
    "import tkinter as tk\n",
    "from tkinter import ttk, font\n",
    "import threading, time\n",
    "from itertools import islice, combinations\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "directory_path = 'data/raw'\n",
    "filenames = sorted(os.listdir(directory_path))\n",
    "print(f\"{len(filenames) * 1000} playlists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# looking at only the first 30,000 playlists\n",
    "fullpaths = [directory_path + '/' + f for f in filenames][0:500]\n",
    "save = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_relationships = {}\n",
    "iteration_times = []\n",
    "\n",
    "song_uris_set = set()\n",
    "\n",
    "for idx, path in enumerate(fullpaths):\n",
    "    start_time = time.time()\n",
    "\n",
    "    with open(path) as f:\n",
    "        mpd_slice = json.load(f)\n",
    "\n",
    "    playlists_data = mpd_slice['playlists']\n",
    "\n",
    "    for playlist in playlists_data:\n",
    "        songs_set = set()\n",
    "        albums_set = set()\n",
    "        artists_set = set()\n",
    "\n",
    "        for track in playlist['tracks']:\n",
    "            song_uri = track['track_uri'].split(':')[-1]\n",
    "            album_uri = track['album_uri'].split(':')[-1]\n",
    "            artist_uri = track['artist_uri'].split(':')[-1]\n",
    "            \n",
    "            songs_set.add(song_uri)\n",
    "            albums_set.add(album_uri)\n",
    "            artists_set.add(artist_uri)\n",
    "\n",
    "        # Compute song-to-song relationships for the current playlist\n",
    "        pair_counts = Counter(combinations(songs_set, 2))\n",
    "        \n",
    "        for (song1, song2), count in pair_counts.items():\n",
    "            song_relationships.setdefault(song1, {}).setdefault(song2, 0)\n",
    "            song_relationships[song1][song2] += count\n",
    "            song_relationships.setdefault(song2, {}).setdefault(song1, 0)\n",
    "            song_relationships[song2][song1] += count\n",
    "\n",
    "    end_time = time.time()\n",
    "    iteration_time = end_time - start_time\n",
    "    iteration_times.append(iteration_time)\n",
    "\n",
    "    if idx % 10 == 0 and idx > 0:\n",
    "        t = np.sum(iteration_times[-10:])\n",
    "        print(f\"processing {idx - 10}-{idx} - time taken {t:.2f}\")\n",
    "\n",
    "print(f'{len(song_relationships)} songs processed')\n",
    "\n",
    "if save:\n",
    "    formatted_time = datetime.now().strftime('%H_%d_%m_%Y')\n",
    "\n",
    "    save_path = os.path.join('song_data', f'{formatted_time}_song_relationships.gz')\n",
    "\n",
    "    with gzip.open(save_path, 'wb') as f:\n",
    "        pickle.dump(song_relationships, f, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "    print(f\"'song_relationships' saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load song_relationships from storage\n",
    "\n",
    "save_path = os.path.join('song_data', '08_13_08_2023_song_relationships.gz')\n",
    "\n",
    "with gzip.open(save_path, 'rb') as f:\n",
    "    song_relationships = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "song_data_map = {}\n",
    "for idx, path in enumerate(fullpaths):\n",
    "    if idx % 10 == 0 and idx > 0:\n",
    "        print(f\"Processed {idx-10}-{idx}\")\n",
    "    with open(path) as f:\n",
    "        mpd_slice = json.load(f)\n",
    "    playlists_data = mpd_slice['playlists']\n",
    "    for playlist in playlists_data:\n",
    "        for track in playlist['tracks']:\n",
    "            song_uri = track['track_uri'].split(':')[-1]\n",
    "            song_name = track['track_name']\n",
    "            album_name = track['album_name']\n",
    "            artist_name = track['artist_name']\n",
    "            if song_uri in song_relationships:\n",
    "                song_data_map[song_uri] = {'song_name': song_name, 'album_name': album_name, 'artist_name': artist_name}\n",
    "\n",
    "print(f'{len(song_data_map)} songs processed')\n",
    "\n",
    "if save:\n",
    "    formatted_time = datetime.now().strftime('%H_%d_%m_%Y')\n",
    "    save_path = os.path.join('song_data', f'{formatted_time}_song_data_map.gz')\n",
    "\n",
    "    with gzip.open(save_path, 'wb') as f:\n",
    "        pickle.dump(song_data_map, f)\n",
    "    print(f\"'song_data_map' saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load song_data_map from storage\n",
    "save_path = os.path.join('song_data', f'08_13_08_2023_song_data_map.gz')\n",
    "\n",
    "with gzip.open(save_path, 'rb') as f:\n",
    "    song_data_map = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_indices = {song_uri: idx for idx, song_uri in enumerate(song_relationships.keys())}\n",
    "\n",
    "if save:\n",
    "    formatted_time = datetime.now().strftime('%H_%d_%m_%Y')\n",
    "    save_path = os.path.join('song_data', f'{formatted_time}_song_indices.gz')\n",
    "    with gzip.open(save_path, 'wb') as f:\n",
    "        pickle.dump(song_indices, f, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "    print(f\"'song_indices' saved to {save_path}\")\n",
    "\n",
    "num_songs = len(song_indices)\n",
    "\n",
    "print(num_songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load song_indices from storage\n",
    "save_path = os.path.join('song_data', f'08_13_08_2023_song_indices.gz')\n",
    "\n",
    "with gzip.open(save_path, 'rb') as f:\n",
    "    song_indices = pickle.load(f)\n",
    "\n",
    "num_songs = len(song_indices)\n",
    "print(num_songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_connections = 0\n",
    "song_with_most_connections = None\n",
    "\n",
    "for song, connections in song_relationships.items():\n",
    "    num_connections = len(connections)\n",
    "    if num_connections > max_connections:\n",
    "        max_connections = num_connections\n",
    "        song_with_most_connections = song\n",
    "\n",
    "print(\"Song with the most connections:\", song_data_map[song_with_most_connections])\n",
    "print(\"Number of connections:\", max_connections)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_matrix = csr_matrix((num_songs, num_songs), dtype=np.int32)\n",
    "\n",
    "def slice_dict(d, start, end):\n",
    "    return dict(islice(d.items(), start, end))\n",
    "\n",
    "def update_matrix(chunk):\n",
    "    global full_matrix\n",
    "    \n",
    "    data = []\n",
    "    row_indices = []                \n",
    "    col_indices = []\n",
    "                                      \n",
    "    for song_uri, relationships in chunk.items():\n",
    "        row_idx = song_indices[song_uri]\n",
    "        for related_song_uri, count in relationships.items():\n",
    "            col_idx = song_indices[related_song_uri]\n",
    "            \n",
    "            # Only consider the upper triangle of the matrix\n",
    "            if row_idx <= col_idx:\n",
    "                data.append(count)\n",
    "                row_indices.append(row_idx)\n",
    "                col_indices.append(col_idx)\n",
    "                \n",
    "                # If it's not on the diagonal, add the symmetric entry\n",
    "                if row_idx != col_idx:\n",
    "                    data.append(count)\n",
    "                    row_indices.append(col_idx)\n",
    "                    col_indices.append(row_idx)\n",
    "\n",
    "    # Create a temporary csr_matrix\n",
    "    temp_matrix = csr_matrix((data, (row_indices, col_indices)), shape=(num_songs, num_songs), dtype=np.int32)\n",
    "    \n",
    "    # Update the full_matrix in-place using the temp_matrix\n",
    "    full_matrix += temp_matrix\n",
    "\n",
    "chunk_size = 1000\n",
    "\n",
    "num_chunks = (num_songs + chunk_size - 1) // chunk_size\n",
    "\n",
    "for start_index in range(0, num_songs, chunk_size):\n",
    "    end_index = min(start_index + chunk_size, num_songs)\n",
    "    current_relationships = slice_dict(song_relationships, start_index, end_index)\n",
    "    update_matrix(current_relationships)\n",
    "    print(f\"processed chunk {start_index//chunk_size + 1}/{num_chunks}\")\n",
    "\n",
    "# Now, the full_matrix is your final cooccurrence_matrix\n",
    "cooccurrence_matrix = full_matrix\n",
    "\n",
    "print(f'finished processing matrix size: {cooccurrence_matrix.shape}')\n",
    "\n",
    "if save:\n",
    "    formatted_time = datetime.now().strftime('%H_%d_%m_%Y')\n",
    "    save_path = os.path.join('song_data', f'{formatted_time}_cooccurrence_matrix.gz')\n",
    "    with gzip.open(save_path, 'wb') as f:\n",
    "        pickle.dump(cooccurrence_matrix, f, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "    print(f\"'cooccurrence_matrix' saved to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparsity(csr_matrix):\n",
    "    total_elements = csr_matrix.shape[0] * csr_matrix.shape[1]\n",
    "    non_zero_elements = csr_matrix.nnz\n",
    "    sparsity = (total_elements - non_zero_elements) / total_elements\n",
    "    return sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load cooccurrence_matrix from storage\n",
    "save_path = os.path.join('song_data', f'15_13_08_2023_cooccurrence_matrix.gz')\n",
    "\n",
    "with gzip.open(save_path, 'rb') as f:\n",
    "    cooccurrence_matrix = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1\n",
    "total_occurrences = np.sum(cooccurrence_matrix)\n",
    "p_i = np.sum(cooccurrence_matrix, axis=1) / total_occurrences\n",
    "p_i = np.asarray(p_i).flatten()\n",
    "p_ij = cooccurrence_matrix / total_occurrences\n",
    "\n",
    "def compute_pmi_for_chunk(start_row, end_row):\n",
    "    # Lists to store data for this chunk\n",
    "    pmi_data_chunk = []\n",
    "    row_indices_chunk = []\n",
    "    col_indices_chunk = []\n",
    "\n",
    "    for i in range(start_row, end_row):\n",
    "        for data_idx in range(p_ij.indptr[i], p_ij.indptr[i + 1]):\n",
    "            j = p_ij.indices[data_idx]\n",
    "\n",
    "            if p_ij.data[data_idx] > 0:  # Avoid log(0)\n",
    "                original_pmi = np.log2(p_ij.data[data_idx] / (p_i[i] * p_i[j]))\n",
    "                pmi_score = original_pmi #- (-(k - 1) * np.log2(p_ij.data[data_idx]))\n",
    "                if pmi_score > 0:\n",
    "                    pmi_data_chunk.append(pmi_score)\n",
    "                    row_indices_chunk.append(i - start_row)  # Adjust the row index relative to the chunk\n",
    "                    col_indices_chunk.append(j)\n",
    "                \n",
    "    return pmi_data_chunk, row_indices_chunk, col_indices_chunk\n",
    "\n",
    "if save:\n",
    "    # Define chunk size\n",
    "    chunk_size = 2000\n",
    "    saved_chunk_files = []\n",
    "    formatted_time = datetime.now().strftime('%H_%d_%m_%Y')\n",
    "\n",
    "    for start in range(0, cooccurrence_matrix.shape[0], chunk_size):\n",
    "        end = min(start + chunk_size, cooccurrence_matrix.shape[0])\n",
    "        print(f\"Processing rows {start} to {end}\")\n",
    "        \n",
    "        data, row, col = compute_pmi_for_chunk(start, end)\n",
    "        chunk_matrix = csr_matrix((data, (row, col)), shape=(end-start, cooccurrence_matrix.shape[1]), dtype=np.float32)\n",
    "\n",
    "        save_path = os.path.join('song_data/pmi', f'{formatted_time}_{start}_{end}_{k}_pmi_matrix.gz')\n",
    "        with gzip.open(save_path, 'wb') as f:\n",
    "            pickle.dump(chunk_matrix, f, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "        saved_chunk_files.append(save_path)\n",
    "\n",
    "    # Combining saved chunks\n",
    "    chunks = []\n",
    "    for chunk_file in saved_chunk_files:\n",
    "        with gzip.open(chunk_file, 'rb') as f:\n",
    "            chunks.append(pickle.load(f))\n",
    "\n",
    "    pmi_matrix = vstack(chunks, format='csr')\n",
    "    print(f'Finished processing matrix size: {pmi_matrix.shape}')\n",
    "\n",
    "else:\n",
    "    chunk_size = 2000\n",
    "    chunks = []\n",
    "\n",
    "    for start in range(0, cooccurrence_matrix.shape[0], chunk_size):\n",
    "        end = min(start + chunk_size, cooccurrence_matrix.shape[0])\n",
    "        print(f\"Processing rows {start} to {end}\")\n",
    "        \n",
    "        data, row, col = compute_pmi_for_chunk(start, end)\n",
    "        chunk_matrix = csr_matrix((data, (row, col)), shape=(end-start, cooccurrence_matrix.shape[1]), dtype=np.float32)\n",
    "        chunks.append(chunk_matrix)\n",
    "        \n",
    "    pmi_matrix = vstack(chunks, format='csr')\n",
    "    print(f'Finished processing matrix size: {pmi_matrix.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load pmi_matrix from storage\n",
    "\n",
    "folder_path = 'song_data/pmi'  # Replace with the path to your folder\n",
    "saved_chunk_files = [folder_path + '/' + f for f in os.listdir(folder_path) if \"16_13_08_2023\" in f]\n",
    "saved_chunk_files = sorted(saved_chunk_files, key = lambda x: int(x.split('_')[5]))\n",
    "chunks = []\n",
    "for chunk_file in saved_chunk_files:\n",
    "    with gzip.open(chunk_file, 'rb') as f:\n",
    "        chunks.append(pickle.load(f))\n",
    "\n",
    "pmi_matrix = vstack(chunks, format='csr')\n",
    "print(f'Finished processing matrix size: {pmi_matrix.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_playlist_vector(playlist_songs, song_indices, num_songs):\n",
    "    if not playlist_songs:\n",
    "        return csr_matrix(np.ones((1, num_songs)))\n",
    "    \n",
    "    indices = [song_indices[song] for song in playlist_songs]\n",
    "    data = np.ones(len(indices))\n",
    "    indptr = np.array([0, len(indices)])\n",
    "    return csr_matrix((data, indices, indptr), shape=(1, num_songs))\n",
    "\n",
    "def compute_scores(user_vector, pmi_matrix):\n",
    "    s = time.time()\n",
    "    scores = user_vector @ pmi_matrix\n",
    "    e = time.time()\n",
    "    print(e - s)\n",
    "    return scores.toarray()[0]\n",
    "\n",
    "# def get_top_recommendations(scores, song_data_map, song_indices, n=10):\n",
    "#     s = time.time()\n",
    "#     top_indices = np.argsort(scores)[-n:][::-1]\n",
    "#     top_songs = [song_data_map[list(song_indices)[i]] for i in top_indices]\n",
    "#     e = time.time()\n",
    "#     print(e - s)\n",
    "#     return top_songs\n",
    "\n",
    "def get_top_recommendations(scores, song_data_map, song_indices, n=10):\n",
    "    s = time.time()\n",
    "    \n",
    "    # Get the top n indices without sorting the entire array\n",
    "    top_indices = np.argpartition(scores, -n)[-n:]\n",
    "    # Now, sort only the top n indices\n",
    "    top_indices_sorted = top_indices[np.argsort(scores[top_indices])][::-1]\n",
    "    \n",
    "    song_indices_list = list(song_indices.keys())\n",
    "    top_songs = [song_data_map[song_indices_list[i]] for i in top_indices_sorted]\n",
    "    \n",
    "    e = time.time()\n",
    "    print(e - s)\n",
    "    return top_songs\n",
    "\n",
    "def recommend_songs_pmi(user_playlist, song_indices, pmi_matrix, song_data_map, n=10):\n",
    "    user_vector = user_playlist_vector(user_playlist, song_indices, num_songs)\n",
    "    scores = compute_scores(user_vector, pmi_matrix)\n",
    "    return get_top_recommendations(scores, song_data_map, song_indices, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SongRecommendationApp(tk.Tk):\n",
    "    def __init__(self, song_data_map):\n",
    "        super().__init__()\n",
    "\n",
    "        default_font = font.nametofont(\"TkDefaultFont\")\n",
    "        default_font.configure(family=\"Courier\")\n",
    "\n",
    "        self.song_data_map = song_data_map\n",
    "        self.uri_map = {self.format_song_display(song_info): uri for uri, song_info in song_data_map.items()}\n",
    "        self.playlist_data = []  # Store song data for sorting\n",
    "\n",
    "        # Filter Frame\n",
    "        self.filter_frame = ttk.Frame(self)\n",
    "        self.filter_frame.pack(pady=10)\n",
    "\n",
    "        # Label and Entry for Song\n",
    "        self.song_label = ttk.Label(self.filter_frame, text=\"Song\")\n",
    "        self.song_label.grid(row=0, column=0, padx=5)\n",
    "        self.song_entry = ttk.Entry(self.filter_frame)\n",
    "        self.song_entry.grid(row=1, column=0, padx=5)\n",
    "\n",
    "        # Label and Entry for Artist\n",
    "        self.artist_label = ttk.Label(self.filter_frame, text=\"Artist\")\n",
    "        self.artist_label.grid(row=0, column=1, padx=5)\n",
    "        self.artist_entry = ttk.Entry(self.filter_frame)\n",
    "        self.artist_entry.grid(row=1, column=1, padx=5)\n",
    "\n",
    "        # Label and Entry for Album\n",
    "        self.album_label = ttk.Label(self.filter_frame, text=\"Album\")\n",
    "        self.album_label.grid(row=0, column=2, padx=5)\n",
    "        self.album_entry = ttk.Entry(self.filter_frame)\n",
    "        self.album_entry.grid(row=1, column=2, padx=5)\n",
    "\n",
    "        # Debounce logic\n",
    "        self.last_time = time.time()\n",
    "\n",
    "        self.search_button = ttk.Button(self.filter_frame, text=\"Search\", command=self.display_search_results)\n",
    "        self.search_button.grid(row=2, columnspan=3, pady=10)\n",
    "\n",
    "        width = 200\n",
    "        # Songs Listbox\n",
    "        self.songs_listbox = tk.Listbox(self, selectmode=tk.SINGLE, width=width, font=(\"Courier\", 10))\n",
    "        self.songs_listbox.pack(pady=10)\n",
    "\n",
    "        # Drag & Drop functionality\n",
    "        self.songs_listbox.bind('<<ListboxSelect>>', self.add_to_playlist)\n",
    "\n",
    "        # Playlist Listbox\n",
    "        self.playlist_listbox = tk.Listbox(self, bg=\"lightblue\", selectmode=tk.SINGLE, width=width, font=(\"Courier\", 10))\n",
    "        self.playlist_listbox.pack(pady=10)\n",
    "\n",
    "        # Number of recommendations\n",
    "        self.n_label = ttk.Label(self, text=\"Number of Recommendations:\")\n",
    "        self.n_label.pack(pady=5)\n",
    "        self.n_entry = ttk.Entry(self)\n",
    "        self.n_entry.pack(pady=5)\n",
    "\n",
    "        # Button to generate recommendations\n",
    "        self.btn_recommend = ttk.Button(self, text=\"Generate Recommendations\", command=self.generate_recommendations)\n",
    "        self.btn_recommend.pack(pady=10)\n",
    "\n",
    "        # Recommendations Listbox\n",
    "        self.recommendations_listbox = tk.Listbox(self, bg=\"lightgreen\", selectmode=tk.SINGLE, width=width, font=(\"Courier\", 10))\n",
    "        self.recommendations_listbox.pack(pady=10)\n",
    "\n",
    "        self.recommendations_listbox.bind('<Double-Button-1>', self.open_in_spotify)\n",
    "\n",
    "        self.btn_refresh = ttk.Button(self, text=\"Refresh\", command=self.refresh)\n",
    "        self.btn_refresh.pack(pady=10)\n",
    "    \n",
    "    def refresh(self):\n",
    "        # Clear all fields\n",
    "        self.song_entry.delete(0, tk.END)\n",
    "        self.artist_entry.delete(0, tk.END)\n",
    "        self.album_entry.delete(0, tk.END)\n",
    "        self.n_entry.delete(0, tk.END)\n",
    "        \n",
    "        # Clear listboxes\n",
    "        self.songs_listbox.delete(0, tk.END)\n",
    "        self.playlist_listbox.delete(0, tk.END)\n",
    "        self.recommendations_listbox.delete(0, tk.END)\n",
    "\n",
    "    def open_in_spotify(self, event):\n",
    "            selected_index = self.recommendations_listbox.curselection()\n",
    "            if selected_index:\n",
    "                selected_song = self.recommendations_listbox.get(selected_index)\n",
    "                song_uri = self.uri_map[selected_song]\n",
    "                webbrowser.open(f\"https://open.spotify.com/track/{song_uri}\")\n",
    "                \n",
    "    def display_search_results(self):\n",
    "        song_query = self.song_entry.get().lower()\n",
    "        artist_query = self.artist_entry.get().lower()\n",
    "        album_query = self.album_entry.get().lower()\n",
    "\n",
    "        self.songs_listbox.delete(0, tk.END)\n",
    "        results = []  # Store the filtered results first\n",
    "\n",
    "        for uri, song_info in self.song_data_map.items():\n",
    "            if song_query in song_info['song_name'].lower() and artist_query in song_info['artist_name'].lower() and album_query in song_info['album_name'].lower():\n",
    "                display_name = self.format_song_display(song_info)\n",
    "                results.append(display_name)\n",
    "\n",
    "        # Sort by album name\n",
    "        results.sort(key=lambda x: self.song_data_map[self.uri_map[x]]['album_name'])\n",
    "\n",
    "        # Display the sorted results\n",
    "        for display_name in results:\n",
    "            self.songs_listbox.insert(tk.END, display_name)\n",
    "\n",
    "        if len(results) > 300:  # If you want to limit the displayed results\n",
    "            self.songs_listbox.delete(301, tk.END)\n",
    "\n",
    "    def format_song_display(self, song_info):\n",
    "        formatted_str = \"{:<65}{:<35}{:<35}\"\n",
    "        f_string = formatted_str.format(song_info['song_name'], song_info['artist_name'], song_info['album_name'])\n",
    "        return f_string\n",
    "\n",
    "    def add_to_playlist(self, event):\n",
    "        selected_index = self.songs_listbox.curselection()\n",
    "        if selected_index:  # This checks if there's any selection at all\n",
    "            selected_song = self.songs_listbox.get(selected_index)\n",
    "            if selected_song not in self.playlist_listbox.get(0, tk.END):  # Prevent duplicates\n",
    "                self.playlist_listbox.insert(tk.END, selected_song)\n",
    "\n",
    "    def generate_recommendations(self):\n",
    "        s = time.time()\n",
    "        playlist_display_names = list(self.playlist_listbox.get(0, tk.END))\n",
    "        playlist_uris = [self.uri_map[display_name] for display_name in playlist_display_names]  # Extract URIs\n",
    "\n",
    "        n = int(self.n_entry.get())\n",
    "        recommended_songs = recommend_songs_pmi(playlist_uris, song_indices, pmi_matrix, song_data_map, n)\n",
    "\n",
    "        self.recommendations_listbox.delete(0, tk.END)\n",
    "        for song in recommended_songs:\n",
    "            formatted_song = self.format_song_display(song)\n",
    "            self.recommendations_listbox.insert(tk.END, formatted_song)\n",
    "        e = time.time()\n",
    "        print(e - s)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = SongRecommendationApp(song_data_map)\n",
    "    app.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
